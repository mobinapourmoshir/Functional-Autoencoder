{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 (simplest): Pass your own basis matrices directly\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def custom_basis_polysin(tpts):\n",
    "    t = tpts.detach().cpu().numpy().flatten()\n",
    "    B = np.column_stack([\n",
    "        np.ones_like(t),\n",
    "        t,\n",
    "        t**2,\n",
    "        np.sin(2*np.pi*t),\n",
    "        np.cos(2*np.pi*t),\n",
    "    ])  # shape [n_time, n_basis]\n",
    "    return torch.tensor(B, dtype=torch.float32)\n",
    "\n",
    "#basis_fc_project = custom_basis_polysin(tpts).to(device)  # [n_time, n_basis]\n",
    "#basis_fc_revert  = custom_basis_polysin(tpts).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Modify build_basis_fc to accept a custom callable\n",
    "from skfda import representation\n",
    "\n",
    "def build_basis_fc(tpts, n_basis=20, basis_type=\"Bspline\", custom_basis_fn=None):\n",
    "    \"\"\"\n",
    "    Returns basis_fc of shape [n_time, n_basis].\n",
    "    If custom_basis_fn is provided, it overrides basis_type.\n",
    "    \"\"\"\n",
    "    if custom_basis_fn is not None:\n",
    "        B = custom_basis_fn(tpts)  # must return torch tensor [n_time, n_basis]\n",
    "        if not torch.is_tensor(B):\n",
    "            B = torch.tensor(B, dtype=torch.float32)\n",
    "        return B.float()\n",
    "\n",
    "    # otherwise, use built-in choices (Bspline/Fourier)\n",
    "    t = tpts.flatten().detach().cpu().numpy()\n",
    "    t_min, t_max = float(t.min()), float(t.max())\n",
    "\n",
    "    if basis_type == \"Bspline\":\n",
    "        basis = representation.basis.BSplineBasis(n_basis=n_basis, order=4)\n",
    "        eval_ = basis(tpts.detach().cpu().numpy(), derivative=0)[:, :, 0]  # [n_time, n_basis]\n",
    "    elif basis_type == \"Fourier\":\n",
    "        basis = representation.basis.Fourier([t_min, t_max], n_basis=n_basis)\n",
    "        eval_ = basis(tpts.detach().cpu().numpy(), derivative=0)[:, :, 0]\n",
    "    else:\n",
    "        raise ValueError(\"basis_type must be 'Bspline' or 'Fourier'\")\n",
    "\n",
    "    return torch.from_numpy(eval_).float()\n",
    "\n",
    "#basis_fc_project = build_basis_fc(tpts, custom_basis_fn=custom_basis_polysin).to(device)\n",
    "#basis_fc_revert  = build_basis_fc(tpts, custom_basis_fn=custom_basis_polysin).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d77dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Use a data-driven basis (PCA basis from the curves)\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def pca_basis_from_data(x, n_basis):\n",
    "    \"\"\"\n",
    "    x: torch tensor [n_subject, n_time]\n",
    "    returns basis [n_time, n_basis] using right singular vectors\n",
    "    \"\"\"\n",
    "    X = x.detach().cpu().numpy()\n",
    "    X = X - X.mean(axis=0, keepdims=True)\n",
    "\n",
    "    # SVD of X: X = U S V^T, V is [n_time, n_time]\n",
    "    U, S, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    B = Vt[:n_basis].T  # [n_time, n_basis]\n",
    "    return torch.tensor(B, dtype=torch.float32)\n",
    "\n",
    "#basis_fc_project = pca_basis_from_data(x, n_basis_project).to(device)\n",
    "#basis_fc_revert  = basis_fc_project.clone()  # often same basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f645379",
   "metadata": {},
   "source": [
    "Important practical notes:\n",
    "\n",
    "1) Shapes must match your project() / revert()\n",
    "\n",
    "If your clean code uses [n_time, n_basis], stick to that everywhere.\n",
    "\n",
    "2) Orthonormal vs non-orthonormal basis\n",
    "\n",
    "Reconstruction with coef @ B.T works for any basis.\n",
    "\n",
    "But the optional “feature loss” MSE(feature, coef) is only meaningful if the basis is orthonormal (as you already commented in your old code). Totally fine to ignore it.\n",
    "\n",
    "3) Want to include a custom smoothing penalty?\n",
    "\n",
    "If your basis isn’t “ordered” (like wavelets), your second-difference penalty may not be meaningful. You can replace it with:\n",
    "\n",
    "- L2 penalty on coefficients\n",
    "\n",
    "- penalty based on derivative matrices\n",
    "\n",
    "- group lasso style penalties, etc."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
